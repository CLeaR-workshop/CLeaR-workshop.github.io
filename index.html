<!DOCTYPE html>

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CLeaR 2022</title>
  <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
  <link href='//fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
  <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  <!-- Latest compiled and minified CSS -->
</head>

<body>
  <section class="page-header">
    <h1 class="project-name">CLeaR 2022</h1>
    <h2 class="project-tagline">The First International Workshop on Combining Learning and Reasoning: Programming Languages, Formalisms, and Representations</h2>
    <h2 class="project-tagline">In conjunction with the 36th AAAI conference on artificial intelligence
      <a href="https://ijcai19.org">(AAAI-2022)</a>, February 22-March 1, 2022, Vancouver, BC, Canada
    </h2>
    <br>
    Workshop Day: TBD,
    Location: TBD
  </section>
  <section>
    <!-- Static navbar -->
    <nav class="navbar navbar-default">
      <div class="container-fluid">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar"
            aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>

        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li class="active"><a href="#overview">Overview</a></li>
            <li><a href="#topics">Topics</a></a></li>
            <li><a href="#schedule">Schedule</a></li>
            <li><a href="#invited-speakers">Invited Speakers</a></li>
            <!--<li><a href="#submission-info">Submission</a></li>!-->
            <li><a href="#accepted-papers">Accepted Paper</a></li>
            <li><a href="#important-dates">Important Dates</a></li>
            <!--li><a href="#demos">Demos</a></li-->
            <!--li><a href="#panel">Panel</a></li-->
            <li><a href="#organizers">Organizers</a></li>
<!--            <li><a href="pastWorkshops.html">Past Workshops</a>-->
          </ul>
        </div>
        <!--/.nav-collapse -->
      </div>
      <!--/.container-fluid -->
    </nav>

  </section>


  <section class="main-content">
    <a id="overview" class="anchor" href="#overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>
    <h2>Overview</h2>

    <p>
      The increased availability of data and novel machine learning methods has sparked an interest in taking learning-based and data-driven approaches in many disciplines such as biology, social sciences, cognitive science, finance, and physics. To solve real-world problems, we require  integration of AI learning paradigms to enable the incorporation of expert knowledge, and dealing with uncertainty or complex structures in learning or inference. This, in turn, leads to a long path between formulating the problem and materializing the learning algorithm. The current practice often falls short in addressing it in a principle way and led to experimentation with variety of models and algorithms. While this gap slows down the progress in the AI field, it also makes it less accessible for domain experts outside the field. This problem calls for formalisms and languages which can integrate the existing disciplines in particular the symbolic and sub-symbolic approaches for combining learning and reasoning.
      In this workshop we look the importance of the integrative paradigms from the lens of real-world applications for making AI accessible to domain experts and provide the means for: 1. High-level and declarative expression of the problem (i.e. the user specifies what she wants to achieve rather than how to achieve it), 2. Incorporating prior knowledge(e.g. laws of physics, or certain biological properties), 3. Reasoning over uncertain data/predictions, 4. Dealing with complex structures such as graphs and relations (e.g. to represent a social network or molecule), 5. Modularity, which allows the components of a program to be easily switched or reused.
    </p>
<!--    <p>-->
<!--    <h4>Related communities</h4>-->
<!--    Over the last few years the research community has tried to address these problems from multiple perspectives, most-->
<!--    notably various approaches based on Probabilistic programming (PP), Logical Programming (LP), Constrained-->
<!--    Conditional models (CCM) and other integrated paradigms such as Probabilistic Logical Programming (PLP) and-->
<!--    Statistical relational learning (SRL). These paradigms and related languages aim at learning over probabilistic-->
<!--    structures and exploiting knowledge in learning. Moreover, in the recent years several Deep Learning tools have-->
<!--    created easy to use abstractions for programming model configurations for deep architectures which can is also-->
<!--    connected to differentiable programming then.-->
<!--    We aim at motivating the need for further research toward a unified framework in this area based on the above-->
<!--    mentioned key existing paradigms as well as other related research such as First-order query languages, deductive-->
<!--    databases (DDB), hybrid optimization and deep architectures for learning from data and knowledge and differentiable-->
<!--    programming in our sense of learning based programs. We are interested in connecting these ideas related to-->
<!--    Declarative Learning Based Programming Paradigm and investigate the required type of languages, representations and-->
<!--    computational models to support such a paradigm. </p>-->

<!--    <h4>Highlight</h4>-->
<!--    Though the theme of this workshop remains generic as in the past versions, we will aim at emphasizing on ideas and-->
<!--    opinions regarding considering domain knowledge in statistical and deep learning architectures and particularly the-->
<!--    program representations to express data and knowledge for machine learning models.-->





    <a id="topics" class="anchor" href="#topics" aria-hidden="true"><span class="octicon octicon-link"></span></a>
    <h2>Topics Summary</h2>

    The main research questions and topics of interest include, but are not limited to:
    <ul>
      <li>Declarative and imperative languages for combining learning and reasoning</li>
      <li>Programming Languages, Domain specific languages, Libraries and software tools for integration of various learning and reasoning paradigms</li>
      <li>Integration of probabilistic inference in training deep models</li>
      <li>Integration of neuro and symbolic approaches</li>
      <li>Integration of logical inference in training deep models</li>
      <li>Using logical inference in deep learning</li>
      <li>Integration of Deep Learning and Relational Learning</li>
      <li>Integration of Deep learning and Constraint programming</li>
      <li>Declarative languages and diffrentiable programming</li>
      <li>Techniques for integration of learning and reasoning</li>
      <li>Integration of declarative and procedural domain knowledge in learning</li>
      <li>Integration of non-differentiable optimization models in learning</li>
      <li>Integration of domain knowledge about   fairness, privacy, etc in designing learning models</li>
    </ul>



<!--    <ul>-->
<!--      <li><strong>Vaishak Belle and Brendan Juba,</strong> <em>Implicitly Learning to Reason in First-Order Logic.</em>-->
<!--      </li>-->
<!--      <li><strong>Brendan Juba,</strong> <em>Query-driven PAC-learning for reasoning.</em></li>-->
<!--      <li><strong>Taisuke Sato and Ryosuke Kojima,</strong> <em>Logical inference as cost minimization in vector-->
<!--          spaces.</em></li>-->
<!--      <li><strong>Tal Friedman and Guy Van den Broeck,</strong> <em>Towards Complex Querying of Probabilistic-->
<!--          Classifiers.</em></li>-->
<!--      <li><strong>Quan Guo, Andrzej Uszok and Parisa Kordjamshidi,</strong> <em>From Ontologies to Learning-Based-->
<!--          Programs.</em></li>-->
<!--      <li><strong>Alberto Camacho, Rodrigo Toro Icarte, Toryn Klassen, Richard Valenzano and Sheila McIlraith,</strong>-->
<!--        <em>LTL and Beyond: Formal Languages for Goal Specification in Reinforcement Learning.</em>-->
<!--      </li>-->
<!--      <li><strong>Sebastijan Dumancic, Tias Guns, Wannes Meert and Hendrik Blockeel,</strong> <em>Learning Relational-->
<!--          Representations with Auto-encoding Logic Programs.</em></li>-->
<!--      <li><strong>Zhe Zeng and Guy Van den Broeck,</strong> <em>Efficient Search-Based Weighted Model Integration.</em>-->
<!--      </li>-->
<!--    </ul>-->

    <a id="submission-info" class="anchor" href="#submission-info" aria-hidden="true"><span
        class="octicon octicon-link"></span></a>
    <h2>Submissions</h2>
    TBD
<!--    We encourage contributions with either a technical paper (IJCAI style, 6 pages without references), a position-->
<!--    statement (IJCAI style, 2 pages maximum) or an abstract of a published work. IJCAI Style files available <a-->
<!--      href="https://www.ijcai.org/authors_kit">here</a>. Please make submissions via EasyChair, <a-->
<!--      href="https://easychair.org/conferences/?conf=delbp2019">here</a>.-->


    <a id="important-dates" class="anchor" href="#important-dates" aria-hidden="true"><span
        class="octicon octicon-link"></span></a>
    <h2>Important Dates</h2>
    <ul>
      <li>SubmissionÂ Deadline: November 12th
      </li>
      <li>Notification: December 4th</li>
      <li>Camera Ready:  December 15th</li>
      <li>Workshop Day:  February 28-March 1</li>
    </ul>
    <p>
      We are open  to the papers that have been submitted to the main conference. However, the reviews should be submitted to us and those will be quickly meta-reviewed.
    </p>

    <a id="organizers" class="anchor" href="#organizers" aria-hidden="true"><span
            class="octicon octicon-link"></span></a>
    <h2>Organizing Committee</h2>

    <table cellspacing="0" cellpadding="0" style="width:100%">
      <tr>
        <td width="32%">
          <li><a href="">Parisa Kordjamshidi</a></li>
        </td>
        <td>Michigan State University, <a href="https://www.ihmc.us">IHMC</a></td>
        <td>kordjams@msu.edu</td>
      </tr>
      <tr>
        <td>
          <li><a href="">Behrouz Babaki</a></li>
        </td>
        <td>Mila/HEC Montreal</td>
        <td>behrouz.babaki@mila.quebec</td>
      </tr>
      <tr>
        <td>
          <li><a href="">Sebastijan DumanÄiÄ</a></li>
        </td>
        <td>KU Leuven</td>
        <td>sebastijan.dumancic@cs.kuleuven.be</td>
      </tr>
      <tr>
        <td>
          <li><a href="">Alex Ratner</a> </li>
        </td>
        <td>University of Washington</td>
        <td>ajratner@cs.washington.edu</td>
      </tr>
      <tr>
        <td>
          <li><a href="">Hossein Rajaby Faghihi</a></li>
        </td>
        <td>Michigan State University</td>
        <td>rajabyfa@msu.edu</td>
      </tr>
      <tr>
        <td>
          <li><a href="">Hamid Karimian</a></li>
        </td>
        <td>Michigan State University</td>
        <td>karimian@msu.edu</td>
      </tr>
    </table>
      <h2>Advising Committee</h2>
      <table>
          <tr>
              <td>
                  <li><a href="">Dan Roth</a></li>
              </td>
              <td>University of Pennsylvania</td>
              <td>danroth@seas.upenn.edu</td>
          </tr>
          <tr>
              <td>
                  <li><a href="">Guy Van Den Broeck</a></li>
              </td>
              <td>University of California Los Angeles</td>
              <td>guyvdb@cs.ucla.edu</td>
          </tr>
      </table>

    <p>Contact: <a href="mailto:clear-workshop@googlegroups.com?Subject=CleaR" target="_top">clear-workshop@googlegroups.com</a></p>

    <a id="program-commitee" class="anchor" href="#program-commitee" aria-hidden="true"><span
            class="octicon octicon-link"></span></a>

    <h2>Program Committee</h2>

    TBD

<!--    <table cellspacing="0" cellpadding="0" float="left">-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="https://web.cs.ucla.edu/~guyvdb/">Guy Van den Broeck</a></li>-->
<!--        </td>-->
<!--        <td>University of California, Los Angeles</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="">Avi Pfeffer</a></li>-->
<!--        </td>-->
<!--        <td>Charles River Analytics</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="http://www.ai.sri.com/%7Ebraz/">Rodrigo de Salvo Braz</a></li>-->
<!--        </td>-->
<!--        <td>SRI International</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="">Tias Guns</a></li>-->
<!--        </td>-->
<!--        <td>Vrije Universiteit Brussel (VUB)</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="https://cs.stanford.edu/~chrismre/">Christopher RÃ©</a></li>-->
<!--        </td>-->
<!--        <td>Stanford University</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="">Pasquale Minervini</a></li>-->
<!--        </td>-->
<!--        <td>University College London</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="">Eli Bingham</a></li>-->
<!--        </td>-->
<!--        <td>Uber AI Labs</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="https://ajratner.github.io/">Alexander Ratner</a></li>-->
<!--        </td>-->
<!--        <td>Stanford University</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="">Golnoosh Farnadi</a></li>-->
<!--        </td>-->
<!--        <td>University of California, Santa Cruz</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="">Behrouz Babaki</a></li>-->
<!--        </td>-->
<!--        <td>Katholieke Universiteit Leuven</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="">Mark Kaminski</a></li>-->
<!--        </td>-->
<!--        <td>University of Oxford</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="">Aneesha Bakharia</a></li>-->
<!--        </td>-->
<!--        <td>The University of Queensland</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="">Nantia Makrynioti</a></li>-->
<!--        </td>-->
<!--        <td>AUEB</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="">Dan Goldwasser</a></li>-->
<!--        </td>-->
<!--        <td>Purdue University</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="">Mehul Bhatt</a></li>-->
<!--        </td>-->
<!--        <td>Ãrebro University, University of Bremen</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="">Stephen Bach</a></li>-->
<!--        </td>-->
<!--        <td>Brown University</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="">Matko BoÅ¡njak</a></li>-->
<!--        </td>-->
<!--        <td>University College London</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>-->
<!--          <li><a href="">Sebastijan Dumancic</a></li>-->
<!--        </td>-->
<!--        <td>Katholieke Universiteit Leuven</td>-->
<!--      </tr>-->
<!--    </table>-->

    <a id="accepted-papers" class="anchor" href="#accepted-papers" aria-hidden="true"><span
            class="octicon octicon-link"></span></a>
    <h2>Accepted Papers</h2>
    TBD

    <a id="schedule" class="anchor" href="#schedule" aria-hidden="true"><span class="octicon octicon-link"></span></a>
    <h2>Schedule</h2>
    TBD

    <!-- <table class="table" style="width:100%">
      <tr class="info">
        <td width="96px">9:00-9:10</td>
        <td>Opening remarks.</td>
        <td>Organizers</td>
      </tr>
      <tr class="success">
        <td>9:10-10:10</td>
        <td><strong>Invited talk.</strong> Discrete Probabilistic Programming from First Principles.

        </td>
        <td>Guy van den Broeck</td>
      </tr>
      <tr>
        <td>10:10-10:30</td>
        <td><strong>Accepted paper 1.</strong> Implicitly Learning to Reason in First-Order Logic. <a
            href="papers/DeLBP-2019_Accepted-1.pdf">[Paper]</a></td>
        <td>Vaishak Belle and Brendan Juba</td>
      </tr>

      <tr class="info">
        <td>10:30-11:00</td>
        <td><strong>Coffee Break.</strong></td>
        <td> </td>
      </tr>

      <tr>
        <td>11:00-11:20</td>
        <td><strong>Accepted paper 2.</strong> Logical inference as cost minimization in vector spaces. <a
            href="papers/DeLBP-2019_Accepted-2.pdf">[Paper]</a></td>
        <td>Taisuke Sato and Ryosuke Kojima</td>
      </tr>
      <tr>
        <td>11:20-11:40</td>
        <td><strong>Accepted paper 3.</strong> From Ontologies to Learning-Based Programs. <a
            href="papers/DeLBP-2019_Accepted-3.pdf">[Paper]</a></td>
        <td>Quan Guo, Andrzej Uszok and Parisa Kordjamshidi</td>
      </tr>
      <tr>
        <td>11:40-12:00</td>
        <td><strong>Accepted paper 4.</strong> Learning Relational Representations with Auto-encoding Logic Programs. <a
            href="papers/DeLBP-2019_Accepted-4.pdf">[Paper]</a></td>
        <td>Sebastijan Dumancic, Tias Guns, Wannes Meert and Hendrik Blockeel</td>
      </tr>
      <tr>
        <td>12:00-12:20</td>
        <td><strong>Accepted paper 5.</strong> Efficient Search-Based Weighted Model Integration. <a
            href="papers/DeLBP-2019_Accepted-5.pdf">[Paper]</a></td>
        <td>Zhe Zeng and Guy Van den Broeck. (Presenter: Paolo Morettin)</td>
      </tr>

      <tr class="info">
        <td>12:20-14:10</td>
        <td><strong>Lunch Break.</strong></td>
        <td> </td>
      </tr>

      <tr class="success">
        <td>14:10-15:10</td>
        <td><strong>Invited talk.</strong> Exploiting Document Intent for Deep Understanding of Text: Case Studies in
          Law and Molecular Biology.
        </td>
        <td>Leora Morgenstern</td>
      </tr>
      <tr>
        <td>15:10-15:30</td>
        <td><strong>Accepted paper 7.</strong> Query-driven PAC-learning for reasoning. <a
            href="papers/DeLBP-2019_Accepted-7.pdf">[Paper]</a></td>
        <td>Brendan Juba</td>
      </tr>
      <tr class="info">
        <td>15:30-16:00</td>
        <td><strong>Coffee Break.</strong></td>
        <td> </td>
      </tr>

      <tr>
        <td>16:00-16:20</td>
        <td><strong>Accepted paper 8.</strong> LTL and Beyond: Formal Languages for Goal Specification in Reinforcement
          Learning. <a href="papers/DeLBP-2019_Accepted-8.pdf">[Paper]</a></td>
        <td>Alberto Camacho, Rodrigo Toro Icarte, Toryn Klassen, Richard Valenzano and Sheila McIlraith</td>
      </tr>
      <tr>
        <td>16:20-17:20</td>
        <td><strong>Panel discussion.</strong> </td>
        <td> </td>
      </tr>
    </table> -->


    <a id="invitedSpeakers" class="anchor" href="#invited-speakers" aria-hidden="true"><span
            class="octicon octicon-link"></span></a>
    <h2>Invited Speakers</h2>
    TBD
    <!--    <ul>-->
    <!--      <li><strong><a href="https://web.cs.ucla.edu/~guyvdb/">Guy Van den Broeck</a>, University of California Los-->
    <!--          Angeles</strong></li>-->
    <!--      <p> <strong> Title. Discrete Probabilistic Programming from First Principles. </strong> </p>-->

    <!--      <p>Abstract: This talk will build up semantics and probabilistic reasoning algorithms for discrete probabilistic-->
    <!--        programs from first principles. We begin by explaining simple semantics for imperative probabilistic programs,-->
    <!--        highlighting how they are different from classical representations of uncertainty in AI, and the possible-->
    <!--        pitfalls along the way. Then we dive into algorithms for reasoning about such programs and exploiting their-->
    <!--        structure, either through abstraction of the probabilistic program, or by compilation into a tractable-->
    <!--        representation for inference.</p>-->

    <!--      <p>Bio: Guy Van den Broeck is an Assistant Professor and Samueli Fellow at UCLA, in the Computer Science-->
    <!--        Department, where he directs the Statistical and Relational Artificial Intelligence (StarAI) lab. His research-->
    <!--        interests are in Machine Learning (Statistical Relational Learning, Tractable Learning, Probabilistic-->
    <!--        Programming), Knowledge Representation and Reasoning (Probabilistic Graphical Models, Lifted Probabilistic-->
    <!--        Inference, Knowledge Compilation, Probabilistic Databases), and Artificial Intelligence in general. Guy is the-->
    <!--        recipient of the IJCAI-19 Computers and Thought Award. His work has been recognized with best paper awards from-->
    <!--        key artificial intelligence venues such as UAI, ILP, and KR, and an outstanding paper honorable mention at AAAI.-->
    <!--        Guy also serves as Associate Editor for the Journal of Artificial Intelligence Research (JAIR).-->
    <!--        Website: http://web.cs.ucla.edu/~guyvdb/</p>-->



    <!--      <li><strong><a href="">Leora Morgenstern</a>, Systems & Technology Research</strong></li>-->

    <!--      <p><strong> Title: Exploiting Document Intent for Deep Understanding of Text: Case Studies in Law and Molecular-->
    <!--          Biology</strong>-->

    <!--      <p>Abstract:Traditional machine reading systems focus on extracting a set of relations (fixed or flexible;-->
    <!--        provided or learned) and their arguments from text. Such reading systems do reasonably well at extracting-->
    <!--        explicit facts from documents. However, they also miss a great deal of information, sometimes the most important-->
    <!--        information in a document.-->
    <!--        I argue in this talk that a system that is able to recognize document intent will be able to extract much more-->
    <!--        information from both unstructured and semi-structured documents. That is because understanding document intent-->
    <!--        can provide information that is only implicit in text. This implicit information can help guide relation and-->
    <!--        entity extraction and support further inferences from extracted triples.-->
    <!--        I discuss two systems developed using this methodology â (1) The TAILCM system, which extract populated-->
    <!--        templates from complex regulatory financial text; and (2) The LTR system, which extracted protein-protein-->
    <!--        reactions from tables of unpredictable format in the molecular biological literature â and suggest how this-->
    <!--        methodology can be extended to other complex documents.-->
    <!--      </p>-->

    <!--      &lt;!&ndash; <p> <strong> Title. TBD </strong> </p> !&ndash;&gt;-->
    <!--      &lt;!&ndash;</p> -->
    <!--<p>-->
    <!--Bio. Sebastian Riedel is a reader in Natural Language Processing and Machine Learning at the University College London (UCL), where he is leading the Machine Reading lab. He is also the head of research at Bloomsbury AI and an Allen Distinguished Investigator. He works in the intersection of Natural Language Processing and Machine Learning, and focuses on teaching machines how to read and reason. He was educated in Hamburg-Harburg (Dipl. Ing) and Edinburgh (MSc., PhD), and worked at the University of Massachusetts Amherst and Tokyo University before joining UCL.-->
    <!--</p>-->

    <!--  <li><strong><a-->
    <!--  href="http://www.cs.cmu.edu/~wcohen/">William Cohen</a>, Carnegie Mellon University</strong></li>-->
    <!--<p> <strong> Probabilistic Logics and Declarative Statistical Learning </strong>-->

    <!--<p>Abstract. TensorLog is a simple probabilistic first-order logic in which logical-->
    <!--queries can be compiled into differentiable functions in a neural-->
    <!--network infrastructure, such as Tensorflow or Theano. This leads to a-->
    <!--close integration of probabilistic logical reasoning with-->
    <!--deep-learning infrastructure: in particular, it enables-->
    <!--high-performance deep learning frameworks to be used for learning the-->
    <!--parameters of a probabilistic logic.  We show how TensorLog's-->
    <!--integration with deep learners allows one to express logical-->
    <!--constraints on learning for tasks such as question-answering against a-->
    <!--knowledge base and semi-supervised learning for network data.-->
    <!--</p>-->
    <!--<p>-->
    <!--Bio. William Cohen received his bachelor's degree in Computer Science from Duke University in 1984, and a PhD in Computer Science from Rutgers University in 1990. From 1990 to 2000 Dr. Cohen worked at AT&T Bell Labs and later AT&T Labs-Research, and from April 2000 to May 2002 Dr. Cohen worked at Whizbang Labs, a company specializing in extracting information from the web. Dr. Cohen is a past president of the International Machine Learning Society. In the past he has also served as an action editor for the the AI and Machine Learning series of books published by Morgan Claypool, for the journal Machine Learning, the journal Artificial Intelligence, the Journal of Machine Learning Research, and the Journal of Artificial Intelligence Research. He was General Chair for the 2008 International Machine Learning Conference, held July 6-9 at the University of Helsinki, in Finland; Program Co-Chair of the 2006 International Machine Learning Conference; and Co-Chair of the 1994 International Machine Learning Conference. Dr. Cohen was also the co-Chair for the 3rd Int'l AAAI Conference on Weblogs and Social Media, which was held May 17-20, 2009 in San Jose, and was the co-Program Chair for the 4rd Int'l AAAI Conference on Weblogs and Social Media. He is a AAAI Fellow, and was a winner of the 2008 the SIGMOD "Test of Time" Award for the most influential SIGMOD paper of 1998, and the 2014 SIGIR "Test of Time" Award for the most influential SIGIR paper of 2002-2004.-->
    <!-- </p>-->
    <!-- <li><strong> <a href="">Avi Pfeffer</a>, Charles River Analytics</strong></li> -->


    <!--<strong> Scruff: A Deep Probabilistic Cognitive Architecture </strong>-->
    <!-- -->
    <!--<p>Abstract. Probabilistic programming is able to build rich models of systems that combine prior knowledge with the ability to learn from data. One of the reasons for the success of deep learning is the ability to discover hidden features of the domain through complex multi-layered, nonlinear functions; another reason is the ability to learn and reason effectively about these functions in a scalable way. Our goal is to develop generative probabilistic programs that have the same properties. -->
    <!-- -->
    <!--Recent trends in cognitive science view perception and action in a unified framework based on downward prediction using a generative probabilistic model and upward propagation of errors. Scruff is intended to be a probabilistic programming cognitive architecture based on this idea. Scruff provides many different mechanisms for accomplishing intelligent behavior, all within a neat generative probabilistic framework. Scruff uses Haskellâs rich type system to create a library of models, where each kind of model is able to support certain kinds of inference efficiently. The type system ensures that only compatible models can be linked together. Current mechanisms include learning parameters via gradient ascent backpropagation (as in deep neural networks), reinforcement learning to perform inference, conditioning on various kinds of evidence, and different ways of computing probabilities. Using Scruff, we are exploring a range of new kinds of deep models, such as deep noisy-or networks, deep probabilistic context free grammars, and deep conditional linear Guassian networks.</p>-->
    <!--<p>-->
    <!--  Bio. Dr. Avi Pfeffer is Chief Scientist at Charles River Analytics. Dr. Pfeffer is a leading researcher on a variety of computational intelligence techniques including probabilistic reasoning, machine learning, and computational game theory. Dr. Pfeffer has developed numerous innovative probabilistic representation and reasoning frameworks, such as probabilistic programming, which enables the development of probabilistic models using the full power of programming languages, and statistical relational learning, which provides the ability to combine probabilistic and relational reasoning. He is the lead developer of Charles River Analyticsâ Figaro probabilistic programming language. As an Associate Professor at Harvard, he developed IBAL, the first general-purpose probabilistic programming language. While at Harvard, he also produced systems for representing, reasoning about, and learning the beliefs, preferences, and decision-making strategies of people in strategic situations. Prior to joining Harvard, he invented object-oriented Bayesian networks and probabilistic relational models, which form the foundation of the field of statistical relational learning. Dr. Pfeffer serves as Action Editor of the Journal of Machine Learning Research and served as Associate Editor of Artificial Intelligence Journal and as Program Chair of the Conference on Uncertainty in Artificial Intelligence. He has published many journal and conference articles and is the author of a text on probabilistic programming. Dr. Pfeffer received his Ph.D. in computer science from Stanford University and his B.A. in computer science from the University of California, Berkeley.-->
    <!-- -->
    <!--</p>-->
    <!--<li> <strong> <a href="">Eli Bingham,</a> Uber AI Labs </strong></li>  -->

    <!--<strong>Pyro: Programmable Probabilistic Programming with Python and PyTorch </strong>-->
    <!--<p>-->
    <!--  Abstract. Most structured probabilistic models in modern AI research are still implemented from scratch as one-off systems, slowing their development and limiting their scope and extensibility.  Universal probabilistic programming languages promise to reduce this burden, but are challenged in practice by more advanced models that often require high-performance inference engines that can be heavily modified in model-specific ways.  We present Pyro, a probabilistic programming language embedded in Python designed to enable such flexibility.  To scale to large datasets and high-dimensional models, Pyro leverages stochastic variational inference algorithms and probability distributions built on top of PyTorch, a modern deep learning framework.  To accommodate complex or model-specific algorithmic behavior, Pyro leverages Poutine, a library of composable building blocks for modifying the behavior of probabilistic programs.  We show that these two features make it possible to use Pyro to successfully implement a range of deep probabilistic models, including Attend-Infer-Repeat (AIR), a recursively structured generative model of images.-->
    <!--  </p>-->
    <!--<p> Bio. Eli Bingham is a research scientist at Uber AI Labs, where he is one of the core developers of the probabilistic programming language Pyro.  He was previously an early employee and research scientist at Geometric Intelligence, which became Uber AI Labs, and a PhD student at NYU.</p>-->
    <!--  </ul>-->

    <!--<a id="accepted-papers" class="anchor" href="#accepted-papers" aria-hidden="true"><span class="octicon octicon-link"></span></a><h2>Invited Papers</h2>-->
    <!--<ul>-->
    <!-- <li> <strong>Alex Ratner, Stephen H. Bach, Henry Ehrenberg, Jason Fries, Sen Wu, Christopher RÃ©,</strong><em> Snorkel: Rapid Training Data Creation with Weak Supervision.</em></li>-->
    <!-- </ul>-->
    <!-- <a id="accepted-papers" class="anchor" href="#accepted-papers" aria-hidden="true"><span class="octicon octicon-link"></span></a><h2>Accepted Papers</h2>-->

    <!--<ul>-->
    <!--<li>-->
    <!--<strong> -->
    <!--Golnoosh Farnadi, Behrouz Babaki and Lise Getoor,</strong><em> Fairness-aware Relational Learning and Inference.</em> </li>-->

    <!--<li> <strong>Michelangelo Diligenti, Soumali Roychowdhury and Marco Gori,</strong><em> Image Classification Using Deep Learning and Prior Knowledge.</em>-->
    <!--</li>-->
    <!-- -->
    <!--&ndash;&gt;-->

    <!--    </ul>-->


    <!--<div>
<table cellspacing="0" cellpadding="0" float="left">
<tr>
<td width="45%">
<li><a href="http://people.cs.kuleuven.be/%7Eguy.vandenbroeck/">Guy
  Van den Broeck</a> </td> <td>University of California, Los Angeles</td></li>
  </tr>
 <tr>
<td><li>Nikolaos Vasiloglou</td><td>Ismion Inc</li></td>
</tr>
  <tr>
<td><li><a href="http://sameersingh.org">Sameer Singh</a></td><td> University of California, Irvine </td></li>
</tr>
<tr>
<td>
<li><a href="http://www.ai.sri.com/%7Ebraz/">Rodrigo de Salvo Braz</a></td><td> SRI International</td></li>
</tr>
<tr>
<td><li>Tias Guns</td><td>Vrije University of Brussels</li></td>
</tr>
<tr>
<td width="47%">
<li> Christos Christodoulopoulos</td> <td>Amazon Cambridge, UK</li></td>
</tr>
<tr>
<td><li>William Wang</td><td>University of California, Santa Barbara</li></td>
</tr>
<tr>
<td><li>Martin Mladenov</td><td>Technical University of Dortmund</li></td>
</tr>
<tr>
<td><li>Kai-Wei Chang</td><td> University of California, Los Angeles</li></td>
</tr>
<tr>
<td><li>Umar Manzoor</td><td> Tulane University</li></td>
</tr>
<tr>
<td><li>Mark Kaminski</td><td> University of Oxford</li></td>
</tr>
<tr>
<td><li>Avi Pfeffer</td><td>Charles River Analytics</li></td>
</tr>
</table>
<p>
<table style="display: inline-block; border: 0;align-content: center;">
<tr>
<td><img style="width: 130px; display: block; height: auto;" src="ihmc_logo.png"></a></td></tr>
</table>
</div>
<a href="https://www.ihmc.us"><img style="width: 140px; height: auto;" src="AS-267480109387779@1440783635465_l.jpeg" align="right"></a>-->

    <footer class="site-footer">

      <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>
        using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a
          href="https://twitter.com/jasonlong">Jason Long</a>.</span>
    </footer>

  </section>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
  <!-- Start of StatCounter Code for Default Guide -->
  <script type="text/javascript">
    var sc_project = 11083511;
    var sc_invisible = 1;
    var sc_security = "2f97c6cf";
    var scJsHost = (("https:" == document.location.protocol) ?
      "https://secure." : "http://www.");
    document.write("<sc" + "ript type='text/javascript' src='" +
      scJsHost +
      "statcounter.com/counter/counter.js'></" + "script>");
  </script>
  <noscript>
    <div class="statcounter"><a title="web analytics" href="http://statcounter.com/" target="_blank"><img
          class="statcounter" src="//c.statcounter.com/11083511/0/2f97c6cf/1/" alt="web
analytics"></a></div>
  </noscript>
  <!-- End of StatCounter Code for Default Guide -->
</body>

</html>
